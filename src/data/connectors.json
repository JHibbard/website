[
  {
    "name": "dlt - Delta Lake interface for SparkR",
    "description": "This package provide readers and writers for the Delta format, DeltaTable merge API, and Delta table builder API for SparkR.",
    "url": "https://dlt.zero323.net/",
    "tags": ["SparkR"],
    "thumbnail": "./images/connectors/dlt.png"
  },
  {
    "name": "Flink/Delta Sink",
    "description": "This connector leverages the Delta Standalone project for Apache Flink to write to Delta Lake tables.",
    "url": "https://github.com/delta-io/connectors/tree/master/flink-connector/",
    "tags": ["Flink"],
    "thumbnail": "./images/connectors/apache-flink-logo.png"
  },
  {
    "name": "Trino/Delta Reader",
    "description": "This connector leverages the Delta Standalone project for Trino to read from Delta Lake tables.",
    "url": "https://github.com/trinodb/trino-hive-apache",
    "tags": ["Trino"],
    "thumbnail": "./images/connectors/trino-logo.png"
  },
  {
    "name": "PrestoDB/Delta Reader",
    "description": "This connector leverages the Delta Standalone project for Trino to read from Delta Lake tables.",
    "url": "https://github.com/prestodb/presto",
    "tags": ["PrestoDB"],
    "thumbnail": "./images/connectors/prestodb-logo.png"
  },
  {
    "name": "Beam/Delta Reader",
    "description": "This connector leverages the Delta Standalone project for Apache Beam to read from Delta Lake tables.",
    "url": "https://github.com/mbenenso/beam-deltalake",
    "tags": ["Beam"],
    "thumbnail": "./images/connectors/apache-beam.png"
  },
  {
    "name": "Delta Standalone",
    "description": "Delta Standalone project is a JVM library to read from and write to Delta Lake tables. Unlike https://github.com/delta-io/delta, this project doesn't use Spark to read tables and it has only a few transitive dependencies. It can be used by any application that cannot use an Apache Spark cluster.",
    "url": "https://github.com/delta-io/connectors",
    "tags": ["Scala", "JVM"],
    "thumbnail": "./images/connectors/delta-standalone.png"
  },
  {
    "name": "Power BI Delta Connector",
    "description": "Reading Delta Lake tables natively in Power BI The provided PowerQuery/M function allows you to read a Delta Lake table directly from any storage supported by PowerBI. Most common storage would be Azure Data Lake Store, Azure Blob Storage, or a local folder or file share.",
    "url": "https://github.com/delta-io/connectors/tree/master/powerbi",
    "tags": ["PowerBI"],
    "thumbnail": "./images/connectors/powerbi.png"
  },
  {
    "name": "Power BI Delta Sharing Connector (beta)",
    "description": "Reading Delta Sharing tables natively in Power BI.",
    "url": "https://docs.microsoft.com/en-us/power-query/connectors/deltasharing",
    "tags": ["PowerBI"],
    "thumbnail": "./images/connectors/powerbi.png"
  },
  {
    "name": "Hive Connector",
    "description": "This project is a library to make Hive read Delta Lake tables. The project provides a uber JAR delta-hive-assembly_-0.2.0.jar to use in Hive. You can use either Scala 2.11 or 2.12. The released JARs are available in the releases page. Please download the uber JAR for the corresponding Scala version you would like to use. You can also use the following instructions to build it as well.",
    "url": "https://github.com/delta-io/connectors",
    "tags": ["Hive"],
    "thumbnail": "./images/connectors/hive.png"
  },
  {
    "name": "SQL Delta Import",
    "description": "sql-delta-import is a utility for importing data from a JDBC source into a Delta Lake table.  This project is part of the delta.io/connectors repo.  For more information, refer to https://tech.scribd.com/blog/2021/introducing-sql-delta-import.html",
    "url": "https://github.com/delta-io/connectors",
    "tags": ["SQL", "JDBC"],
    "thumbnail": "./images/connectors/sql.png"
  },
  {
    "name": "Kafka Delta Ingest",
    "description": "The kafka-delta-ingest project aims to build a highly efficient daemon for streaming data through Apache Kafka into Delta Lake. This project is currently highly experimental and evolving in tandem with the delta-rs bindings.",
    "url": "https://github.com/delta-io/kafka-delta-ingest",
    "tags": ["Kafka"],
    "thumbnail": "./images/connectors/kafka.png"
  },
  {
    "name": "Delta Rust API",
    "description": "An experimental interface to Delta Lake for Rust. This library provides low level access to Delta tables and is intended to be used with data processing frameworks like datafusion, ballista, rust-dataframe, vega, etc. It can also act as the basis for native bindings in other languages such as Python, Ruby or Golang. This project is still very early and only read operations are supported at the moment.",
    "url": "https://github.com/delta-io/delta-rs",
    "tags": ["Rust", "Python"],
    "thumbnail": "./images/connectors/rust.png"
  },
  {
    "name": "Presto",
    "description": "Presto supports reading from external tables using a manifest file, which is a text file containing the list of data files to read for querying a table. When an external table is defined in the Hive metastore using manifest files, Presto can use the list of files in the manifest rather than finding the files by directory listing.",
    "url": "https://docs.delta.io/latest/presto-integration.html",
    "tags": ["Presto"],
    "thumbnail": "./images/connectors/presto.png"
  },
  {
    "name": "Athena",
    "description": "Athena supports reading from external tables using a manifest file, which is a text file containing the list of data files to read for querying a table. When an external table is defined in the Hive metastore using manifest files, Athena can use the list of files in the manifest rather than finding the files by directory listing.",
    "url": "https://docs.delta.io/latest/presto-integration.html",
    "tags": ["Athena", "AWS"],
    "thumbnail": "./images/connectors/athena.png"
  },
  {
    "name": "Snowflake",
    "description": "A Delta table can be read by Snowflake using a manifest file, which is a text file containing the list of data files to read for querying a Delta table.",
    "url": "https://docs.delta.io/latest/snowflake-integration.html",
    "tags": ["Snowflake"],
    "thumbnail": "./images/connectors/snowflake.png"
  },
  {
    "name": "Redshift",
    "description": "A Delta table can be read by Redshift Spectrum using a manifest file, which is a text file containing the list of data files to read for querying a Delta table.",
    "url": "https://docs.delta.io/latest/redshift-spectrum-integration.html",
    "tags": ["Redshift", "AWS"],
    "thumbnail": "./images/connectors/redshift.png"
  }
]
